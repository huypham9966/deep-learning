{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "import numpy as np\n",
    "import math as math \n",
    "import tensorflow as tf\n",
    "import graph_synthesis as gs\n",
    "from random_mini_batches import random_mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    \n",
    "    def __init__(self, inputdat, labeldat, testdat, testlabeldat, layer_dims, decayrate = 0.99,\n",
    "                 l2reg = 1e-3, learning_rate = 0.008, batch_size = 128, epoch_nums = 5000):\n",
    "        \n",
    "        #Data\n",
    "        self.inputdat = inputdat\n",
    "        self.labeldat = labeldat\n",
    "        self.testdat = testdat\n",
    "        self.testlabeldat = testlabeldat\n",
    "        self.num_eg = inputdat.shape[0]\n",
    "        self.inputdim = inputdat.shape[1]\n",
    "        \n",
    "        #Hyperparameters\n",
    "        self.layer_dims = layer_dims\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epoch_nums = epoch_nums\n",
    "        self.l2reg = l2reg  \n",
    "        self.decayrate = decayrate \n",
    "        \n",
    "        #Initialize\n",
    "        tf.reset_default_graph()\n",
    "        self.initdata()\n",
    "        \n",
    "        #Create graph\n",
    "        self.output = self.model()\n",
    "        self.optimizer, self.cost = self.train()\n",
    "        self.prediction, self.accuracy = self.test()\n",
    "        self.summary_op = self.create_summaries()\n",
    "        \n",
    "        #Run Tensorflow\n",
    "        config = tf.ConfigProto(allow_soft_placement = True, log_device_placement = True, device_count = {'GPU': 1})\n",
    "        self.sess = tf.Session(config = config)\n",
    "        init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "        self.sess.run(init)\n",
    "        \n",
    "        #Tensorboard setup\n",
    "        self.writer = tf.summary.FileWriter('./CNNSave',  (self.sess).graph)\n",
    "        \n",
    "        #Train model \n",
    "        self.graph_classifier()\n",
    "        self.prediction_num, self.error_num = self.evaluate(\"train\") \n",
    "        \n",
    "    def  create_summaries(self):\n",
    "        with tf.name_scope(\"summaries\"):\n",
    "            tf.summary.scalar(\"loss\", self.cost)\n",
    "            #tf.summary.scalar(\"output\", self.output)\n",
    "            tf.summary.scalar(\"accuracy\", self.accuracy)\n",
    "            tf.summary.histogram(\"histogram_loss\", self.cost)\n",
    "            #tf.summary.histogram(\"histogram_loss\", self.output)\n",
    "            summary_op = tf.summary.merge_all()\n",
    "        return summary_op\n",
    "    \n",
    "    def initdata(self):\n",
    "        self.tflearnrate = tf.placeholder(tf.float32, name = \"learnrate\")\n",
    "        self.mode = tf.placeholder(tf.bool, name = \"mode\")\n",
    "        self.input = tf.placeholder(tf.float32, shape = [None, self.inputdim, self.inputdim, 1], name = \"input\")\n",
    "        self.label = tf.placeholder(tf.float32, shape = [None, 1], name = \"label\")\n",
    "\n",
    "    \n",
    "    def model(self):\n",
    "        layer_dims = self.layer_dims\n",
    "        layers = {}\n",
    "        \n",
    "        #Convolution 1 \n",
    "        scope = 'convolayers' + str(1) \n",
    "        with tf.variable_scope(scope):\n",
    "            conv11 = tf.layers.conv2d(inputs=self.input, filters=32, kernel_size=[3, 3],\n",
    "                                     padding=\"same\", activation=None)\n",
    "            conv11 = tf.contrib.layers.batch_norm(conv11, is_training = self.mode, scope = 'batchnorm1')\n",
    "            conv11 = tf.nn.relu(conv11, 'relu1')\n",
    "            \n",
    "            conv12 = tf.layers.conv2d(inputs=conv11, filters=32, kernel_size = [5, 5], \n",
    "                                     padding=\"same\", activation=None)\n",
    "            conv12 = tf.contrib.layers.batch_norm(conv12, is_training = self.mode, scope = 'batchnorm2')\n",
    "            conv12 = tf.nn.relu(conv12, 'relu2')\n",
    "            \n",
    "            pool1 = conv12\n",
    "            #pool1 = tf.layers.max_pooling2d(inputs=conv12, pool_size=[2, 2], strides=1)\n",
    "        \n",
    "        #Convolution 2 \n",
    "        scope = 'convolayers' + str(2) \n",
    "        with tf.variable_scope(scope):\n",
    "            conv21 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[3, 3],\n",
    "                                     padding=\"same\", activation=None)\n",
    "            conv21 = tf.contrib.layers.batch_norm(conv21, is_training = self.mode, scope = 'batchnorm1')\n",
    "            conv21 = tf.nn.relu(conv21, 'relu1')\n",
    "            \n",
    "            conv22 = tf.layers.conv2d(inputs=conv21, filters=64, kernel_size = [5, 5], \n",
    "                                     padding=\"same\", activation=None)\n",
    "            conv22 = tf.contrib.layers.batch_norm(conv22, is_training = self.mode, scope = 'batchnorm2')\n",
    "            conv22 = tf.nn.relu(conv22, 'relu2')\n",
    "            \n",
    "            pool2 = tf.layers.max_pooling2d(inputs=conv22, pool_size=[2, 2], strides=2)\n",
    "        \n",
    "        #Convolution 3\n",
    "        scope = 'convolayers' + str(3) \n",
    "        with tf.variable_scope(scope):\n",
    "            conv31 = tf.layers.conv2d(inputs=pool2, filters=128, kernel_size=[3, 3],\n",
    "                                     padding=\"same\", activation=None)\n",
    "            conv31 = tf.contrib.layers.batch_norm(conv31, is_training = self.mode, scope = 'batchnorm1')\n",
    "            conv31 = tf.nn.relu(conv31, 'relu1')\n",
    "            \n",
    "            conv32 = tf.layers.conv2d(inputs=conv31, filters=128, kernel_size = [3, 3], \n",
    "                                     padding=\"same\", activation=None)\n",
    "            conv32 = tf.contrib.layers.batch_norm(conv32, is_training = self.mode, scope = 'batchnorm2')\n",
    "            conv32 = tf.nn.relu(conv32, 'relu2')\n",
    "            \n",
    "            pool3 = tf.layers.max_pooling2d(inputs=conv32, pool_size=[2, 2], strides=2)\n",
    "            \n",
    "        size = pool3.shape[1]\n",
    "        pool_flat = tf.reshape(pool3, [-1, size * size * 128])\n",
    "    \n",
    "        layers[0] = pool_flat\n",
    "        #Dense layers\n",
    "        for i in range(len(layer_dims)-1):\n",
    "            if (i < len(layer_dims) - 2):\n",
    "                scope = 'denselayers' + str(i+1)\n",
    "                with tf.variable_scope(scope):\n",
    "                    layers[i+1] = tf.contrib.layers.fully_connected(num_outputs = layer_dims[i+1], \\\n",
    "                                                        activation_fn = None, inputs = layers[i], scope = 'dense')\n",
    "                    layers[i+1] = tf.contrib.layers.batch_norm(layers[i+1], is_training = self.mode, scope = 'batchnorm')\n",
    "                    layers[i+1] = tf.nn.relu(layers[i+1], 'relu')\n",
    "            else:\n",
    "                scope = 'denselayers' + str(i+1)\n",
    "                with tf.variable_scope(scope):\n",
    "                    layers[len(layer_dims)-1] = tf.layers.dense(units = layer_dims[len(layer_dims)-1], \\\n",
    "                                                    activation = tf.nn.sigmoid, inputs = layers[len(layer_dims)-2])\n",
    "        \n",
    "        output = layers[len(layer_dims)-1]\n",
    "        return output \n",
    "    \n",
    "    def train(self):\n",
    "        #Saver for data \n",
    "        self.saver = tf.train.Saver()\n",
    "        self.global_step = tf.Variable(0, dtype = tf.int32, trainable = False, name = 'global_step')\n",
    "        \n",
    "        #Define cost \n",
    "        gap_loss = tf.reduce_max(self.output) - tf.reduce_min(self.output)\n",
    "        reg_loss = self.l2reg * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables()) \n",
    "        cost = (tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = self.output, labels = self.label)) + \\\n",
    "                                                                                            reg_loss)\n",
    "        #cost = (tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = self.output, labels = self.label)) + \\\n",
    "                                                                                            #reg_loss) * 1/(0.01+gap_loss)\n",
    "        \n",
    "        #Batch Normalization\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=self.tflearnrate).minimize(cost, global_step = self.global_step)\n",
    "            \n",
    "        return optimizer, cost \n",
    "    \n",
    "    def test(self):\n",
    "        prediction = tf.greater(self.output, tf.constant(0.5, dtype = tf.float32))\n",
    "        with tf.name_scope('accuracy'):\n",
    "            with tf.name_scope('correct_prediction'):\n",
    "                correct_prediction = tf.equal(tf.cast(prediction, dtype = tf.float32), self.label)\n",
    "            with tf.name_scope('accuracy'):\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "                tf.summary.scalar('accuracy', accuracy)\n",
    "        return prediction, accuracy\n",
    "    \n",
    "    def graph_classifier(self):\n",
    "        curlearnrate = self.learning_rate\n",
    "        step = 0 \n",
    "        for epochs in range(self.epoch_nums):\n",
    "            output = []\n",
    "            mini_batch = random_mini_batches(self.inputdat, self.labeldat, self.batch_size)\n",
    "            curlearnrate = curlearnrate * self.decayrate \n",
    "            for dat in mini_batch:\n",
    "                step = step + 1 \n",
    "                _, cost, output, summary = self.sess.run([self.optimizer, self.cost, self.output, self.summary_op], \n",
    "                                                feed_dict = {self.input: dat[0], self.label: dat[1], \\\n",
    "                                                             self.mode: True, self.tflearnrate: curlearnrate})\n",
    "                (self.writer).add_summary(summary, global_step = step)\n",
    "            if ((epochs+1) % 50 == 0):\n",
    "                \n",
    "                _, errortrain = self.evaluate(\"train\")\n",
    "                output, cost, accuracy = self.sess.run([self.output, self.cost, self.accuracy], \\\n",
    "                        feed_dict = {self.input: self.inputdat, self.label: self.labeldat, \\\n",
    "                                     self.mode: False, self.tflearnrate: curlearnrate})\n",
    "                (self.saver).save(self.sess, 'checkpoints/CNN', global_step=self.global_step)\n",
    "                _, errortest = self.evaluate(\"test\")\n",
    "                print(\"epoch\", epochs + 1, \"    |    \", \"cost\", \"%.6e\" % cost, \"    |    \", \n",
    "                      \"error train\", \"%.3f\" % (errortrain * 100), \"    |    \", \"error test\", \"%.3f\" % (errortest * 100), \n",
    "                      \"   |   \", \"output gap\", \"%.6e\" % (np.max(output) - np.min(output)))\n",
    "            \n",
    "                #if ((epochs+1) % 200 == 0):\n",
    "                #    print(output[0], output[len(output)-1])\n",
    "    def evaluate(self, mode):\n",
    "        #Get predictions\n",
    "        if mode == \"train\":\n",
    "            predictions = self.sess.run([self.prediction], \n",
    "                                    feed_dict = {self.input: self.inputdat, self.label: self.labeldat, \\\n",
    "                                                 self.mode: False})\n",
    "        else:\n",
    "            predictions = self.sess.run([self.prediction], \n",
    "                                    feed_dict = {self.input: self.testdat, self.label: self.testlabeldat, \\\n",
    "                                                 self.mode: False})\n",
    "        predictions = np.array(predictions).reshape((self.num_eg,1))\n",
    "        predictions = predictions.astype(int)\n",
    "        \n",
    "        #Compute error\n",
    "        error = np.sum((predictions - self.labeldat)**2)/self.num_eg\n",
    "        #print(\"error \" + mode, error * 100)\n",
    "        \n",
    "        return predictions, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0     |     cost 1.827605e+00     |     error train 0.500     |     error test 0.500\n",
      "epoch 1     |     cost 1.874896e+00     |     error train 0.500     |     error test 0.500\n",
      "epoch 2     |     cost 1.816928e+00     |     error train 0.500     |     error test 0.500\n",
      "epoch 3     |     cost 1.703061e+00     |     error train 0.500     |     error test 0.500\n",
      "epoch 4     |     cost 1.575176e+00     |     error train 0.500     |     error test 0.500\n",
      "epoch 5     |     cost 1.457390e+00     |     error train 0.500     |     error test 0.500\n",
      "epoch 6     |     cost 1.364465e+00     |     error train 0.500     |     error test 0.500\n",
      "epoch 7     |     cost 1.293939e+00     |     error train 0.500     |     error test 0.500\n",
      "epoch 8     |     cost 1.232232e+00     |     error train 0.499     |     error test 0.500\n",
      "epoch 9     |     cost 1.209748e+00     |     error train 0.500     |     error test 0.500\n",
      "epoch 10     |     cost 1.150408e+00     |     error train 0.486     |     error test 0.497\n",
      "epoch 11     |     cost 9.917666e-01     |     error train 0.268     |     error test 0.346\n",
      "epoch 12     |     cost 1.022014e+00     |     error train 0.314     |     error test 0.349\n",
      "epoch 13     |     cost 1.101864e+00     |     error train 0.499     |     error test 0.500\n",
      "epoch 14     |     cost 9.385498e-01     |     error train 0.227     |     error test 0.295\n",
      "epoch 15     |     cost 9.139792e-01     |     error train 0.236     |     error test 0.332\n",
      "epoch 16     |     cost 8.908271e-01     |     error train 0.180     |     error test 0.290\n",
      "epoch 17     |     cost 8.743857e-01     |     error train 0.190     |     error test 0.314\n",
      "epoch 18     |     cost 8.819281e-01     |     error train 0.274     |     error test 0.339\n",
      "epoch 19     |     cost 8.785603e-01     |     error train 0.200     |     error test 0.289\n",
      "epoch 20     |     cost 8.962048e-01     |     error train 0.357     |     error test 0.419\n",
      "epoch 21     |     cost 9.222140e-01     |     error train 0.321     |     error test 0.368\n",
      "epoch 22     |     cost 9.385633e-01     |     error train 0.395     |     error test 0.413\n",
      "epoch 23     |     cost 9.879797e-01     |     error train 0.498     |     error test 0.500\n",
      "epoch 24     |     cost 9.199869e-01     |     error train 0.486     |     error test 0.487\n",
      "epoch 25     |     cost 9.186140e-01     |     error train 0.481     |     error test 0.492\n",
      "epoch 26     |     cost 8.959764e-01     |     error train 0.377     |     error test 0.424\n",
      "epoch 27     |     cost 9.050316e-01     |     error train 0.494     |     error test 0.496\n",
      "epoch 28     |     cost 8.870892e-01     |     error train 0.469     |     error test 0.474\n",
      "epoch 29     |     cost 8.384304e-01     |     error train 0.321     |     error test 0.403\n",
      "epoch 30     |     cost 8.629125e-01     |     error train 0.422     |     error test 0.435\n",
      "epoch 31     |     cost 8.119193e-01     |     error train 0.168     |     error test 0.265\n",
      "epoch 32     |     cost 7.789379e-01     |     error train 0.130     |     error test 0.256\n",
      "epoch 33     |     cost 7.787839e-01     |     error train 0.154     |     error test 0.277\n",
      "epoch 34     |     cost 8.072705e-01     |     error train 0.312     |     error test 0.378\n",
      "epoch 35     |     cost 7.842050e-01     |     error train 0.162     |     error test 0.290\n",
      "epoch 36     |     cost 8.722371e-01     |     error train 0.859     |     error test 0.747\n",
      "epoch 37     |     cost 8.583704e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 38     |     cost 8.533384e-01     |     error train 0.479     |     error test 0.469\n",
      "epoch 39     |     cost 8.728218e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 40     |     cost 8.390913e-01     |     error train 0.560     |     error test 0.529\n",
      "epoch 41     |     cost 8.739881e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 42     |     cost 8.398649e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 43     |     cost 9.022043e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 44     |     cost 9.207611e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 45     |     cost 9.022951e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 46     |     cost 9.260070e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 47     |     cost 9.066194e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 48     |     cost 8.399956e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 49     |     cost 8.405949e-01     |     error train 0.493     |     error test 0.489\n",
      "epoch 50     |     cost 8.138551e-01     |     error train 0.343     |     error test 0.386\n",
      "epoch 51     |     cost 8.598139e-01     |     error train 0.496     |     error test 0.496\n",
      "epoch 52     |     cost 8.769314e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 53     |     cost 9.395058e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 54     |     cost 9.303604e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 55     |     cost 9.208962e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 56     |     cost 9.295191e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 57     |     cost 9.233534e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 58     |     cost 9.153957e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 59     |     cost 9.048989e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 60     |     cost 8.590193e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 61     |     cost 8.334849e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 62     |     cost 8.207307e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 63     |     cost 8.607566e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 64     |     cost 8.745424e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 65     |     cost 8.102568e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 66     |     cost 8.680187e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 67     |     cost 8.471856e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 68     |     cost 8.258697e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 69     |     cost 8.297991e-01     |     error train 0.487     |     error test 0.486\n",
      "epoch 70     |     cost 8.329080e-01     |     error train 0.499     |     error test 0.500\n",
      "epoch 71     |     cost 8.215632e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 72     |     cost 9.343340e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 73     |     cost 9.366391e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 74     |     cost 9.328924e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 75     |     cost 7.865407e-01     |     error train 0.444     |     error test 0.468\n",
      "epoch 76     |     cost 7.980371e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 77     |     cost 7.966378e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 78     |     cost 8.149728e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 79     |     cost 7.617591e-01     |     error train 0.248     |     error test 0.298\n",
      "epoch 80     |     cost 7.281293e-01     |     error train 0.168     |     error test 0.261\n",
      "epoch 81     |     cost 7.550179e-01     |     error train 0.500     |     error test 0.499\n",
      "epoch 82     |     cost 7.269650e-01     |     error train 0.190     |     error test 0.284\n",
      "epoch 83     |     cost 8.089797e-01     |     error train 0.499     |     error test 0.497\n",
      "epoch 84     |     cost 7.878190e-01     |     error train 0.342     |     error test 0.381\n",
      "epoch 85     |     cost 7.600311e-01     |     error train 0.418     |     error test 0.431\n",
      "epoch 86     |     cost 7.510694e-01     |     error train 0.340     |     error test 0.375\n",
      "epoch 87     |     cost 7.471117e-01     |     error train 0.329     |     error test 0.369\n",
      "epoch 88     |     cost 7.666693e-01     |     error train 0.414     |     error test 0.443\n",
      "epoch 89     |     cost 7.734344e-01     |     error train 0.146     |     error test 0.233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90     |     cost 7.373697e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 91     |     cost 7.500931e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 92     |     cost 7.499864e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 93     |     cost 7.451941e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 94     |     cost 7.654312e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 95     |     cost 7.687459e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 96     |     cost 7.366279e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 97     |     cost 7.833034e-01     |     error train 0.261     |     error test 0.310\n",
      "epoch 98     |     cost 8.007814e-01     |     error train 0.487     |     error test 0.479\n",
      "epoch 99     |     cost 7.265248e-01     |     error train 0.419     |     error test 0.424\n",
      "epoch 100     |     cost 7.410748e-01     |     error train 0.486     |     error test 0.477\n",
      "epoch 101     |     cost 7.310765e-01     |     error train 0.474     |     error test 0.463\n",
      "epoch 102     |     cost 7.468045e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 103     |     cost 8.017237e-01     |     error train 0.494     |     error test 0.491\n",
      "epoch 104     |     cost 8.110338e-01     |     error train 0.499     |     error test 0.499\n",
      "epoch 105     |     cost 7.313033e-01     |     error train 0.226     |     error test 0.306\n",
      "epoch 106     |     cost 7.717811e-01     |     error train 0.213     |     error test 0.302\n",
      "epoch 107     |     cost 7.384257e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 108     |     cost 7.961659e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 109     |     cost 7.600504e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 110     |     cost 7.410105e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 111     |     cost 7.711866e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 112     |     cost 7.820054e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 113     |     cost 7.916596e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 114     |     cost 7.942728e-01     |     error train 0.493     |     error test 0.489\n",
      "epoch 115     |     cost 7.410402e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 116     |     cost 7.589496e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 117     |     cost 7.798073e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 118     |     cost 7.897376e-01     |     error train 0.290     |     error test 0.340\n",
      "epoch 119     |     cost 7.899209e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 120     |     cost 7.647756e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 121     |     cost 7.386877e-01     |     error train 0.500     |     error test 0.500\n",
      "epoch 122     |     cost 7.475967e-01     |     error train 0.500     |     error test 0.500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-d2c6d0ef8f38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#Fully connected model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mCNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"graphs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"graphs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m350\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#Test Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-a82583fd89d9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputdat, labeldat, testdat, testlabeldat, layer_dims, decayrate, l2reg, learning_rate, batch_size, epoch_nums)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m#Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-a82583fd89d9>\u001b[0m in \u001b[0;36mgraph_classifier\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputdat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabeldat\u001b[0m\u001b[0;34m,\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtflearnrate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcurlearnrate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'checkpoints/CNN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrortest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m                 print(\"epoch\", epochs, \"    |    \", \"cost\", \"%.6e\" % cost, \"    |    \", \n\u001b[1;32m    174\u001b[0m                       \"error train\", \"%.3f\" % errortrain, \"    |    \", \"error test\", \"%.3f\" % errortest)\n",
      "\u001b[0;32m<ipython-input-51-a82583fd89d9>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m             predictions = self.sess.run([self.prediction], \n\u001b[1;32m    185\u001b[0m                                     feed_dict = {self.input: self.testdat, self.label: self.testlabeldat, \\\n\u001b[0;32m--> 186\u001b[0;31m                                                  self.mode: False})\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_eg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpdeep/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpdeep/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpdeep/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpdeep/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpdeep/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if  __name__ == \"__main__\":\n",
    "    \n",
    "    num_eg = 1000\n",
    "    vertex = 16\n",
    "    inputdim = vertex * vertex\n",
    "    \n",
    "    #train ensemble \n",
    "    #data = gs.generate_ensemble([int(num_eg/2), int(num_eg/2)], vertex, [1/3, 1/2])\n",
    "    data = gs.generate_ensemble_v2(num_eg, vertex)\n",
    "    #test ensemble\n",
    "    #testdata = gs.generate_ensemble([int(num_eg/2), int(num_eg/2)], vertex, [1/3, 1/2])\n",
    "    testdata = gs.generate_ensemble_v2(num_eg, vertex)\n",
    "    #reformat \n",
    "    data[\"graphs\"] = data[\"graphs\"].reshape((num_eg, vertex, vertex, 1))\n",
    "    testdata[\"graphs\"] = testdata[\"graphs\"].reshape((num_eg, vertex, vertex, 1))\n",
    "    \n",
    "    #Fully connected model \n",
    "    CNN = CNN(data[\"graphs\"], data[\"labels\"], testdata[\"graphs\"], testdata[\"labels\"], [inputdim,350,100,50,1])\n",
    "    \n",
    "    #Test Model \n",
    "    #FullNN.inputdat = testdata[\"graphs\"]\n",
    "    #FullNN.labeldat = testdata[\"labels\"]\n",
    "    #FullNN.trainmode = False\n",
    "    #FullNN.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
